{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 전체 데이터 -> 일자별 데이터로 변환(성별,연령,국적통합)"
      ],
      "metadata": {
        "id": "evcDcjXF3dRy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQp0vat_3Zz_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from glob import glob\n",
        "import os\n",
        "\n",
        "# 파일 경로와 패턴\n",
        "base_path = '/content/drive/MyDrive/여의도_불꽃축제_데이터/결측값 제거 데이터/'  # 원본 데이터의 경로로 수정\n",
        "output_path = '/content/drive/MyDrive/여의도_불꽃축제_데이터/성별,연령,국적 통합 데이터/'  # 저장할 경로로 수정\n",
        "\n",
        "# 결과 저장 경로 확인 및 생성\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "# 파일 목록\n",
        "csv_files = glob(base_path + 'KSR_SJUNIV_TRIP_YYD_0000000000*_cleaned.csv')\n",
        "\n",
        "# 전체 데이터를 결합할 데이터프레임\n",
        "combined_data = pd.DataFrame()\n",
        "\n",
        "# 각 파일을 처리하여 결합\n",
        "for file in csv_files:\n",
        "    # CSV 파일을 읽습니다\n",
        "    data = pd.read_csv(file)\n",
        "\n",
        "    # 데이터를 필요한 열을 기준으로 그룹화하여 총 유동인구 수를 구합니다\n",
        "    data_grouped = data.groupby(['DPR_CELL_ID', 'ARV_CELL_ID', 'P_YYYYMMDD']).agg({\n",
        "        'DPR_MT10_UNIT_TM': 'first',\n",
        "        'DPR_X_AXIS_WGS': 'first',\n",
        "        'DPR_Y_AXIS_WGS': 'first',\n",
        "        'ARV_MT10_UNIT_TM': 'first',\n",
        "        'ARV_X_AXIS_WGS': 'first',\n",
        "        'ARV_Y_AXIS_WGS': 'first',\n",
        "        'POPL_CNT': 'sum'  # 유동인구 수 총합\n",
        "    }).reset_index()\n",
        "\n",
        "    # 필요한 열만 선택하여 새로운 데이터프레임에 추가\n",
        "    output_columns = ['P_YYYYMMDD', 'DPR_MT10_UNIT_TM', 'DPR_CELL_ID', 'DPR_X_AXIS_WGS', 'DPR_Y_AXIS_WGS',\n",
        "                      'ARV_MT10_UNIT_TM', 'ARV_CELL_ID', 'ARV_X_AXIS_WGS', 'ARV_Y_AXIS_WGS', 'POPL_CNT']\n",
        "    processed_data = data_grouped[output_columns]\n",
        "\n",
        "    # 결합된 데이터에 추가\n",
        "    combined_data = pd.concat([combined_data, processed_data], ignore_index=True)\n",
        "\n",
        "# 날짜별로 데이터를 나누어 CSV로 저장\n",
        "unique_dates = combined_data['P_YYYYMMDD'].unique()  # P_YYYYMMDD 열을 기준으로 분리\n",
        "for date in unique_dates:\n",
        "    date_filtered_data = combined_data[combined_data['P_YYYYMMDD'] == date]\n",
        "    output_filename = os.path.join(output_path, f'{date}.csv')  # 경로 포함 파일명 저장\n",
        "    date_filtered_data.to_csv(output_filename, index=False)\n",
        "\n",
        "    # 저장된 경로와 파일명을 출력\n",
        "    print(f\"파일이 저장되었습니다: {output_filename}\")\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"전체 데이터를 처리하여 {len(unique_dates)}개의 파일로 분할 저장했습니다.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 일자별 -> 시간별 통합(1시간 단위)"
      ],
      "metadata": {
        "id": "O7mDoTeV3xWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Read the combined data (replace 'combined_output.csv' with actual combined file if needed)\n",
        "data = pd.read_csv('/content/drive/MyDrive/여의도_불꽃축제_데이터/성별,연령,국적 통합 데이터/2023-10-07.csv')  # Replace with the actual file name if different\n",
        "\n",
        "# 1. Convert DPR_MT10_UNIT_TM to 24-hour format with only time\n",
        "data['DPR_MT10_UNIT_TM'] = pd.to_datetime(data['DPR_MT10_UNIT_TM'], errors='coerce').dt.strftime('%H:%M:%S')\n",
        "\n",
        "# 2. Handle potential NaN values and convert to strings for further processing\n",
        "data['DPR_MT10_UNIT_TM'] = data['DPR_MT10_UNIT_TM'].fillna('00:00:00')\n",
        "\n",
        "# 3. Adjust DPR_MT10_UNIT_TM so that times are bucketed correctly (e.g., 23:00:01 to 23:59:59 -> 00:00:00)\n",
        "def adjust_to_hour_bucket(time_str):\n",
        "    \"\"\"Adjusts a time string to represent the next appropriate hour bucket, wrapping around 00:00:00 for late-night entries.\"\"\"\n",
        "    time = datetime.strptime(time_str, '%H:%M:%S')\n",
        "    # Special handling for times close to midnight\n",
        "    if time.hour == 23 and (time.minute > 0 or time.second > 0):\n",
        "        return '00:00:00'\n",
        "    # Increment by 1 hour if not exactly at the hour\n",
        "    if time.minute > 0 or time.second > 0:\n",
        "        time += timedelta(hours=1)\n",
        "    return time.replace(minute=0, second=0).strftime('%H:%M:%S')\n",
        "\n",
        "# Apply the adjustment function to DPR_MT10_UNIT_TM\n",
        "data['DPR_MT10_UNIT_TM'] = data['DPR_MT10_UNIT_TM'].apply(adjust_to_hour_bucket)\n",
        "\n",
        "# 4. Group by 'DPR_CELL_ID', 'ARV_CELL_ID', 'P_YYYYMMDD', and 'DPR_MT10_UNIT_TM' and sum POPL_CNT\n",
        "grouped_data = data.groupby(['DPR_CELL_ID', 'ARV_CELL_ID', 'P_YYYYMMDD', 'DPR_MT10_UNIT_TM'], as_index=False).agg({\n",
        "    'POPL_CNT': 'sum',\n",
        "    'DPR_X_AXIS_WGS': 'first',\n",
        "    'DPR_Y_AXIS_WGS': 'first',\n",
        "    'ARV_MT10_UNIT_TM': 'first',\n",
        "    'ARV_X_AXIS_WGS': 'first',\n",
        "    'ARV_Y_AXIS_WGS': 'first'\n",
        "})\n",
        "\n",
        "# 5. Split and save data based on P_YYYYMMDD and DPR_MT10_UNIT_TM\n",
        "output_path = \"/content/drive/MyDrive/여의도_불꽃축제_데이터/시간별 인구수 통합 데이터/\"  # 저장할 폴더 경로\n",
        "\n",
        "for dpr_time in grouped_data['DPR_MT10_UNIT_TM'].unique():\n",
        "    subset = grouped_data[grouped_data['DPR_MT10_UNIT_TM'] == dpr_time]\n",
        "    for date in subset['P_YYYYMMDD'].unique():\n",
        "        filename = f\"{date}_{dpr_time.replace(':', '')}.csv\"\n",
        "        date_subset = subset[subset['P_YYYYMMDD'] == date]\n",
        "\n",
        "        # 지정된 경로로 파일 저장\n",
        "        file_path = os.path.join(output_path, filename)\n",
        "        date_subset.to_csv(file_path, index=False)\n",
        "        print(f\"파일이 저장되었습니다: {file_path}\")"
      ],
      "metadata": {
        "id": "0j-FbUiT3ykM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}