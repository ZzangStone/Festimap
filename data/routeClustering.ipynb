{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 클러스터링용 시간 통합"
      ],
      "metadata": {
        "id": "ujf0M0jTv4gq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCrIE8ghvwuc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# CSV 파일 읽기\n",
        "input_file = \"/content/drive/MyDrive/여의도_불꽃축제_데이터/지역 데이터/경로분해/2023/경로분해_4.csv\"  # 실제 파일 경로로 변경\n",
        "output_file = \"/content/drive/MyDrive/여의도_불꽃축제_데이터/지역 데이터/클러스터링/4번지역_경로분해_시간통합.csv\"  # 출력 파일 경로 설정\n",
        "\n",
        "# 데이터 로드\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# 노드 좌표 및 다음 노드 좌표를 묶어 그룹화\n",
        "df_grouped = df.groupby(\n",
        "    ['노드X좌표', '노드Y좌표', '다음노드X좌표', '다음노드Y좌표'],\n",
        "    as_index=False\n",
        ")['유동인구'].sum()\n",
        "\n",
        "# 결과 저장\n",
        "df_grouped.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
        "\n",
        "print(f\"새로운 CSV 파일이 생성되었습니다: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Means"
      ],
      "metadata": {
        "id": "cFqrxLwyv8B7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset (assuming your file is named 'data.csv' and located in the current working directory)\n",
        "df = pd.read_csv('/content/output.csv')  # Change '/content/data.csv' to your file path\n",
        "\n",
        "# Select relevant columns for clustering\n",
        "X = df[['노드X좌표', '노드Y좌표', '유동인구']]\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Apply K-Means Clustering\n",
        "kmeans = KMeans(n_clusters=6, random_state=42)\n",
        "kmeans.fit(X_scaled)\n",
        "\n",
        "# Add cluster labels to the original dataframe\n",
        "df['Cluster'] = kmeans.labels_\n",
        "\n",
        "# Plotting the clusters\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(df['노드X좌표'], df['노드Y좌표'], c=df['Cluster'], cmap='viridis', marker='o')\n",
        "plt.colorbar(label='Cluster')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "A6N4zEAnv-9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DBSCAN"
      ],
      "metadata": {
        "id": "KEI0xiX7wCUh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1번 지역"
      ],
      "metadata": {
        "id": "NpXYbYeZwE-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset (replace with your correct file path)\n",
        "df = pd.read_csv('/content/drive/MyDrive/여의도_불꽃축제_데이터/지역 데이터/경로분해/2023/경로분해_1.csv')  # Adjust path as needed\n",
        "\n",
        "# Randomly sample 1/5 of the data\n",
        "df_sampled = df.sample(frac=1/6, random_state=42)  # Adjust 'random_state' for reproducibility\n",
        "\n",
        "# Select relevant columns for clustering\n",
        "X = df_sampled[['노드X좌표', '노드Y좌표', '유동인구']]\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Apply DBSCAN with adjusted parameters\n",
        "dbscan = DBSCAN(eps=0.7, min_samples=4)  # Increase eps and reduce min_samples\n",
        "dbscan.fit(X_scaled)\n",
        "\n",
        "# Add cluster labels to the sampled dataframe\n",
        "df_sampled['Cluster'] = dbscan.labels_\n",
        "\n",
        "# Plotting the clusters\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# DBSCAN assigns -1 to noise points, which we can plot separately for better visualization\n",
        "clusters = df_sampled['Cluster'].unique()\n",
        "for cluster in clusters:\n",
        "    if cluster == -1:  # Noise\n",
        "        plt.scatter(\n",
        "            df_sampled[df_sampled['Cluster'] == cluster]['노드X좌표'],\n",
        "            df_sampled[df_sampled['Cluster'] == cluster]['노드Y좌표'],\n",
        "            c='red', label='Noise', marker='x', alpha=0.5\n",
        "        )\n",
        "    else:  # Clusters\n",
        "        plt.scatter(\n",
        "            df_sampled[df_sampled['Cluster'] == cluster]['노드X좌표'],\n",
        "            df_sampled[df_sampled['Cluster'] == cluster]['노드Y좌표'],\n",
        "            label=f'Cluster {cluster}', alpha=0.6\n",
        "        )\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('노드X좌표')\n",
        "plt.ylabel('노드Y좌표')\n",
        "plt.title('DBSCAN Clustering (Adjusted Parameters)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HXdPpEWmwEAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2번 지역"
      ],
      "metadata": {
        "id": "KsdCmQd4wJ-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset (replace with your correct file path)\n",
        "df = pd.read_csv('/content/drive/MyDrive/여의도_불꽃축제_데이터/지역 데이터/경로분해/2023/경로분해_2.csv')  # Adjust path as needed\n",
        "\n",
        "# Randomly sample 1/5 of the data\n",
        "df_sampled = df.sample(frac=1/6, random_state=42)  # Adjust 'random_state' for reproducibility\n",
        "\n",
        "# Select relevant columns for clustering\n",
        "X = df_sampled[['노드X좌표', '노드Y좌표', '유동인구']]\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Apply DBSCAN with adjusted parameters\n",
        "dbscan = DBSCAN(eps=0.7, min_samples=4)  # Increase eps and reduce min_samples\n",
        "dbscan.fit(X_scaled)\n",
        "\n",
        "# Add cluster labels to the sampled dataframe\n",
        "df_sampled['Cluster'] = dbscan.labels_\n",
        "\n",
        "# Plotting the clusters\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# DBSCAN assigns -1 to noise points, which we can plot separately for better visualization\n",
        "clusters = df_sampled['Cluster'].unique()\n",
        "for cluster in clusters:\n",
        "    if cluster == -1:  # Noise\n",
        "        plt.scatter(\n",
        "            df_sampled[df_sampled['Cluster'] == cluster]['노드X좌표'],\n",
        "            df_sampled[df_sampled['Cluster'] == cluster]['노드Y좌표'],\n",
        "            c='red', label='Noise', marker='x', alpha=0.5\n",
        "        )\n",
        "    else:  # Clusters\n",
        "        plt.scatter(\n",
        "            df_sampled[df_sampled['Cluster'] == cluster]['노드X좌표'],\n",
        "            df_sampled[df_sampled['Cluster'] == cluster]['노드Y좌표'],\n",
        "            label=f'Cluster {cluster}', alpha=0.6\n",
        "        )\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('노드X좌표')\n",
        "plt.ylabel('노드Y좌표')\n",
        "plt.title('DBSCAN Clustering (Adjusted Parameters)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BfVH4qYPwJkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3번 지역"
      ],
      "metadata": {
        "id": "cSNdNS3FwVyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset (replace with your correct file path)\n",
        "df = pd.read_csv('/content/drive/MyDrive/여의도_불꽃축제_데이터/지역 데이터/경로분해/2023/경로분해_3.csv')  # Adjust path as needed\n",
        "\n",
        "# Randomly sample 1/5 of the data\n",
        "df_sampled = df.sample(frac=1/6, random_state=42)  # Adjust 'random_state' for reproducibility\n",
        "\n",
        "# Select relevant columns for clustering\n",
        "X = df_sampled[['노드X좌표', '노드Y좌표', '유동인구']]\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Apply DBSCAN with adjusted parameters\n",
        "dbscan = DBSCAN(eps=0.7, min_samples=4)  # Increase eps and reduce min_samples\n",
        "dbscan.fit(X_scaled)\n",
        "\n",
        "# Add cluster labels to the sampled dataframe\n",
        "df_sampled['Cluster'] = dbscan.labels_\n",
        "\n",
        "# Plotting the clusters\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# DBSCAN assigns -1 to noise points, which we can plot separately for better visualization\n",
        "clusters = df_sampled['Cluster'].unique()\n",
        "for cluster in clusters:\n",
        "    if cluster == -1:  # Noise\n",
        "        plt.scatter(\n",
        "            df_sampled[df_sampled['Cluster'] == cluster]['노드X좌표'],\n",
        "            df_sampled[df_sampled['Cluster'] == cluster]['노드Y좌표'],\n",
        "            c='red', label='Noise', marker='x', alpha=0.5\n",
        "        )\n",
        "    else:  # Clusters\n",
        "        plt.scatter(\n",
        "            df_sampled[df_sampled['Cluster'] == cluster]['노드X좌표'],\n",
        "            df_sampled[df_sampled['Cluster'] == cluster]['노드Y좌표'],\n",
        "            label=f'Cluster {cluster}', alpha=0.6\n",
        "        )\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('노드X좌표')\n",
        "plt.ylabel('노드Y좌표')\n",
        "plt.title('DBSCAN Clustering (Adjusted Parameters)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "__S6G-WzwX5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4번 지역"
      ],
      "metadata": {
        "id": "RUDaeknPwakJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset (replace with your correct file path)\n",
        "df = pd.read_csv('/content/drive/MyDrive/여의도_불꽃축제_데이터/지역 데이터/경로분해/2023/경로분해_4.csv')  # Adjust path as needed\n",
        "\n",
        "# Randomly sample 1/5 of the data\n",
        "df_sampled = df.sample(frac=1/6, random_state=42)  # Adjust 'random_state' for reproducibility\n",
        "\n",
        "# Select relevant columns for clustering\n",
        "X = df_sampled[['노드X좌표', '노드Y좌표', '유동인구']]\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Apply DBSCAN with adjusted parameters\n",
        "dbscan = DBSCAN(eps=0.7, min_samples=4)  # Increase eps and reduce min_samples\n",
        "dbscan.fit(X_scaled)\n",
        "\n",
        "# Add cluster labels to the sampled dataframe\n",
        "df_sampled['Cluster'] = dbscan.labels_\n",
        "\n",
        "# Plotting the clusters\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# DBSCAN assigns -1 to noise points, which we can plot separately for better visualization\n",
        "clusters = df_sampled['Cluster'].unique()\n",
        "for cluster in clusters:\n",
        "    if cluster == -1:  # Noise\n",
        "        plt.scatter(\n",
        "            df_sampled[df_sampled['Cluster'] == cluster]['노드X좌표'],\n",
        "            df_sampled[df_sampled['Cluster'] == cluster]['노드Y좌표'],\n",
        "            c='red', label='Noise', marker='x', alpha=0.5\n",
        "        )\n",
        "    else:  # Clusters\n",
        "        plt.scatter(\n",
        "            df_sampled[df_sampled['Cluster'] == cluster]['노드X좌표'],\n",
        "            df_sampled[df_sampled['Cluster'] == cluster]['노드Y좌표'],\n",
        "            label=f'Cluster {cluster}', alpha=0.6\n",
        "        )\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('노드X좌표')\n",
        "plt.ylabel('노드Y좌표')\n",
        "plt.title('DBSCAN Clustering (Adjusted Parameters)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aVQDPSySwcca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 메인경로 추출"
      ],
      "metadata": {
        "id": "OpraUNBpwXiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1번, 2번 CSV 파일 경로\n",
        "file_path_1 = '/content/filtered_clusters_33_34_35_36.csv'  # 1번 CSV 파일 경로\n",
        "file_path_2 = '/content/drive/MyDrive/여의도_불꽃축제_데이터/지역 데이터/경로분해/2023/경로분해_1.csv'  # 2번 CSV 파일 경로\n",
        "\n",
        "# CSV 파일 읽기\n",
        "df1 = pd.read_csv(file_path_1)\n",
        "df2 = pd.read_csv(file_path_2)\n",
        "\n",
        "# 1번 파일의 좌표를 모아놓기\n",
        "unique_coordinates = set(\n",
        "    df1['노드X좌표'].astype(str) + ',' + df1['노드Y좌표'].astype(str)\n",
        ").union(\n",
        "    df1['다음노드X좌표'].astype(str) + ',' + df1['다음노드Y좌표'].astype(str)\n",
        ")\n",
        "\n",
        "# 2번 파일에서 필터링\n",
        "filtered_rows = []\n",
        "for _, row in df2.iterrows():\n",
        "    node_coords = f\"{row['노드X좌표']},{row['노드Y좌표']}\"\n",
        "    next_node_coords = f\"{row['다음노드X좌표']},{row['다음노드Y좌표']}\"\n",
        "    if node_coords in unique_coordinates or next_node_coords in unique_coordinates:\n",
        "        filtered_rows.append(row)\n",
        "\n",
        "# 필터링된 데이터프레임 생성\n",
        "filtered_df = pd.DataFrame(filtered_rows)\n",
        "\n",
        "# 결과 확인\n",
        "print(\"Filtered Data:\")\n",
        "print(filtered_df)\n",
        "\n",
        "# 필터링된 데이터 저장\n",
        "filtered_output_path = '4번.csv'\n",
        "filtered_df.to_csv(filtered_output_path, index=False)\n",
        "print(f\"Filtered data saved to {filtered_output_path}\")\n"
      ],
      "metadata": {
        "id": "kpXdOvwhwbwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 시각화"
      ],
      "metadata": {
        "id": "fS-Z4ERjwpL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import folium\n",
        "\n",
        "# CSV 파일 경로\n",
        "file_path = '/content/drive/MyDrive/여의도_불꽃축제_데이터/메인경로/2번.csv'  # 여기에 CSV 파일 경로 입력\n",
        "\n",
        "# CSV 파일 읽기\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# 지도 초기화 (중심 좌표는 첫 번째 노드로 설정)\n",
        "map_center = [df['노드Y좌표'].iloc[0], df['노드X좌표'].iloc[0]]\n",
        "m = folium.Map(location=map_center, zoom_start=16)\n",
        "\n",
        "# 경로 추가: 노드 좌표와 다음 노드 좌표를 선으로 연결\n",
        "for _, row in df.iterrows():\n",
        "    start = (row['노드Y좌표'], row['노드X좌표'])\n",
        "    end = (row['다음노드Y좌표'], row['다음노드X좌표'])\n",
        "\n",
        "    # 경로를 지도에 추가\n",
        "    folium.PolyLine([start, end], color='red', weight=5, opacity=0.7).add_to(m)\n",
        "\n",
        "# 지도 출력\n",
        "m\n"
      ],
      "metadata": {
        "id": "Yz15R8t2wqje"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}